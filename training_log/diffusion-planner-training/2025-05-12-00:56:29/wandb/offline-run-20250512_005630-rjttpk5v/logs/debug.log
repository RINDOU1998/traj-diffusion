2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_setup.py:_flush():68] Current SDK version is 0.19.10
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_setup.py:_flush():68] Configure stats pid to 6590
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_setup.py:_flush():68] Loading settings from /root/.config/wandb/settings
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_setup.py:_flush():68] Loading settings from /root/traj-diffusion/wandb/settings
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_init.py:setup_run_log_directory():724] Logging user logs to ./training_log/diffusion-planner-training/2025-05-12-00:56:29/wandb/offline-run-20250512_005630-rjttpk5v/logs/debug.log
2025-05-12 00:56:30,849 INFO    MainThread:6590 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to ./training_log/diffusion-planner-training/2025-05-12-00:56:29/wandb/offline-run-20250512_005630-rjttpk5v/logs/debug-internal.log
2025-05-12 00:56:30,852 INFO    MainThread:6590 [wandb_init.py:init():852] calling init triggers
2025-05-12 00:56:30,852 INFO    MainThread:6590 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-05-12 00:56:30,852 INFO    MainThread:6590 [wandb_init.py:init():893] starting backend
2025-05-12 00:56:31,079 INFO    MainThread:6590 [wandb_init.py:init():897] sending inform_init request
2025-05-12 00:56:31,128 INFO    MainThread:6590 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-12 00:56:31,128 INFO    MainThread:6590 [wandb_init.py:init():907] backend started and connected
2025-05-12 00:56:31,134 INFO    MainThread:6590 [wandb_init.py:init():1002] updated telemetry
2025-05-12 00:56:31,165 INFO    MainThread:6590 [wandb_init.py:init():1026] communicating run to backend with 90.0 second timeout
2025-05-12 00:56:31,247 INFO    MainThread:6590 [wandb_init.py:init():1101] starting run threads in backend
2025-05-12 00:56:31,368 INFO    MainThread:6590 [wandb_run.py:_console_start():2566] atexit reg
2025-05-12 00:56:31,368 INFO    MainThread:6590 [wandb_run.py:_redirect():2414] redirect: wrap_raw
2025-05-12 00:56:31,372 INFO    MainThread:6590 [wandb_run.py:_redirect():2483] Wrapping output streams.
2025-05-12 00:56:31,372 INFO    MainThread:6590 [wandb_run.py:_redirect():2506] Redirects installed.
2025-05-12 00:56:31,374 INFO    MainThread:6590 [wandb_init.py:init():1147] run started, returning control to user process
2025-05-12 00:56:31,375 INFO    MainThread:6590 [wandb_run.py:_config_callback():1429] config_cb None None {'root': '/root/dataset', 'train_batch_size': 32, 'val_batch_size': 32, 'shuffle': True, 'persistent_workers': True, 'gpus': 1, 'monitor': 'val_minFDE', 'save_top_k': 5, 'historical_steps': 20, 'future_steps': 30, 'num_modes': 6, 'rotate': True, 'node_dim': 2, 'edge_dim': 2, 'embed_dim': 128, 'num_heads': 8, 'dropout': 0.1, 'num_temporal_layers': 4, 'num_global_layers': 3, 'local_radius': 50, 'parallel': False, 'lr': 0.0005, 'weight_decay': 0.0001, 'T_max': 64, 'name': 'diffusion-planner-training', 'save_dir': '.', 'augment_prob': 0.5, 'normalization_file_path': 'normalization.json', 'use_data_augment': False, 'num_workers': 8, 'pin_mem': True, 'seed': 3407, 'train_epochs': 100, 'save_utd': 20, 'batch_size': 32, 'learning_rate': 0.0005, 'warm_up_epoch': 5, 'encoder_drop_path_rate': 0.1, 'decoder_drop_path_rate': 0.1, 'alpha_planning_loss': 1.0, 'device': 'cuda', 'use_ema': False, 'encoder_depth': 3, 'decoder_depth': 3, 'hidden_dim': 256, 'diffusion_model_type': 'x_start', 'predicted_neighbor_num': 10, 'resume_model_path': None, 'use_wandb': False, 'notes': '', 'ddp': False, 'port': '22323', 'state_normalizer': None, 'observation_normalizer': None}
2025-05-12 00:56:31,376 INFO    MainThread:6590 [wandb_run.py:_tensorboard_callback():1638] tensorboard callback: ./training_log/diffusion-planner-training/2025-05-12-00:56:29//tb, True
2025-05-12 00:56:35,257 INFO    MsgRouterThr:6590 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 0 handles.
